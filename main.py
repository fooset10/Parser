import requests
from bs4 import BeautifulSoup
import time
import random
import sys

def parse_habr_articles(pages=1):
    base_url = "https://habr.com/ru/articles/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    articles = []

    for page_num in range(1, pages + 1):
        # –ù–æ–≤–∞—è —Å—Ö–µ–º–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: ?page=2, ?page=3 –∏ —Ç.–¥.
        url = f"{base_url}?page={page_num}"
        print(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")

        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            if "captcha" in response.url.lower() or "cloudflare" in response.text.lower():
                print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞ –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                break

            soup = BeautifulSoup(response.text, "lxml")

            # –ù–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –Ω–∞ –Ω–æ—è–±—Ä—å 2025:
            posts = soup.find_all("div", {"data-test-id": "article-snippet"})

            if not posts:
                print("‚ùó –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü –∏–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.")
                break

            for post in posts:
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫–∞
                title_tag = post.find("a", {"data-test-id": "article-title-link"})
                if not title_tag:
                    continue

                title = title_tag.get_text(strip=True)
                link = title_tag["href"]
                if link.startswith("/"):
                    link = "https://habr.com" + link

                # –ê–≤—Ç–æ—Ä
                author_tag = post.find("a", {"data-test-id": "article-author-link"})
                author = author_tag.get_text(strip=True) if author_tag else "–ê–Ω–æ–Ω–∏–º"

                # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                time_tag = post.find("time")
                published = time_tag["datetime"] if time_tag else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

                articles.append({
                    "title": title,
                    "link": link,
                    "author": author,
                    "published": published
                })

            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(posts)} —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(random.uniform(1.5, 3.0))

        except requests.exceptions.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
            break
        except Exception as e:
            print(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            break

    return articles


if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –•–∞–±—Ä–∞...")
    data = parse_habr_articles(pages=2)

    if not data:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        sys.exit(1)

    print(f"\nüìÑ –ü–æ–ª—É—á–µ–Ω–æ {len(data)} —Å—Ç–∞—Ç–µ–π. –ü–µ—Ä–≤—ã–µ 5:\n")
    for item in data[:5]:
        print(f"üìå {item['title']}")
        print(f"üë§ –ê–≤—Ç–æ—Ä: {item['author']}")
        print(f"üìÖ –î–∞—Ç–∞: {item['published']}")
        print(f"üîó –°—Å—ã–ª–∫–∞: {item['link']}\n")
        print("-" * 80)