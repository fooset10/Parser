import logging
import asyncio
import random
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart, Command
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.exceptions import TelegramBadRequest

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
API_TOKEN = '8288944295:AAFgN0cYP2Hz1qZVVSsBguQ2tul3p4oES80'
OWNER_ID = 123456789  # üîë –ó–ê–ú–ï–ù–ò–¢–ï –Ω–∞ –≤–∞—à Telegram user_id!

# === –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–ï ===
logging.basicConfig(level=logging.INFO)

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
bot = Bot(token=API_TOKEN)
dp = Dispatcher()

# === –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ===
user_games = {}
game_stats = {"total_games": 0, "total_guesses": 0}

# === –°–ü–ò–°–û–ö –ú–ï–ú–û–í ===
MEME_URLS = [
    "https://i.imgur.com/4QbL9yA.jpg",
    "https://i.imgur.com/JXe9eDf.jpg",
    "https://i.imgur.com/3Vv4iKQ.jpg",
    "https://i.imgur.com/5B7Tq6m.jpg",
    "https://i.imgur.com/7sK4vJz.jpg",
]

# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def get_main_keyboard(user_id: int = None):
    keyboard = [
        [
            InlineKeyboardButton(text="üëã –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ", callback_data="greet"),
            InlineKeyboardButton(text="‚ùì –ü–æ–º–æ—â—å", callback_data="help"),
        ],
        [
            InlineKeyboardButton(text="üé≤ –°–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ", callback_data="random_number"),
            InlineKeyboardButton(text="üé≠ –°–ª—É—á–∞–π–Ω—ã–π –º–µ–º", callback_data="random_meme"),
        ],
        [
            InlineKeyboardButton(text="üéÆ –ù–∞—á–∞—Ç—å –∏–≥—Ä—É", callback_data="start_game"),
        ],
        [
            InlineKeyboardButton(text="üóû Habr", callback_data="latest_habr"),
            InlineKeyboardButton(text="üî• –¢–æ–ø-3 Habr", callback_data="top3_habr"),
        ],
        [
            InlineKeyboardButton(text="üì∞ –°–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏", callback_data="news_menu"),
            InlineKeyboardButton(text="üìÖ –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è", callback_data="datetime"),
        ],
        [
            InlineKeyboardButton(text="üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data="stats"),
        ]
    ]

    if user_id == OWNER_ID:
        keyboard.append([
            InlineKeyboardButton(text="üîí –°–µ–∫—Ä–µ—Ç", callback_data="secret")
        ])

    return InlineKeyboardMarkup(inline_keyboard=keyboard)


def get_news_sources_keyboard():
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="üá∑üá∫ Lenta.ru", callback_data="news_lenta"),
            InlineKeyboardButton(text="üì∞ Meduza", callback_data="news_meduza"),
        ],
        [
            InlineKeyboardButton(text="üåç BBC", callback_data="news_bbc"),
            InlineKeyboardButton(text="üåê Reuters", callback_data="news_reuters"),
        ],
        [
            InlineKeyboardButton(text="üí° VC.ru", callback_data="news_vc"),
            InlineKeyboardButton(text="üë®‚Äçüíª TProger", callback_data="news_tproger"),
        ],
        [
            InlineKeyboardButton(text="üì∞ RIA", callback_data="news_ria"),
            InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_main"),
        ]
    ])


def escape_markdown_v2(text: str) -> str:
    if not text:
        return ""
    escape_chars = r'\_*[]()~`>#+-=|{}.!'
    return ''.join('\\' + c if c in escape_chars else c for c in str(text))


# === –ü–ê–†–°–ò–ù–ì –°–¢–ê–¢–ï–ô –ò –ù–û–í–û–°–¢–ï–ô ===

# --- Habr (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å) ---
def get_latest_habr_article():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://habr.com/ru/articles/", headers=headers, timeout=10)
        response.raise_for_status()
        if "captcha" in response.url or "cloudflare" in response.text.lower():
            return None
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.find("div", {"data-test-id": "article-snippet"})
        if not article: return None
        title_tag = article.find("a", {"data-test-id": "article-title-link"})
        if not title_tag: return None
        title = title_tag.get_text(strip=True)
        link = "https://habr.com" + title_tag["href"] if title_tag["href"].startswith("/") else title_tag["href"]
        author_tag = article.find("a", {"data-test-id": "article-author-link"})
        author = author_tag.get_text(strip=True) if author_tag else "–ê–Ω–æ–Ω–∏–º"
        lead_tag = article.find("p", {"data-test-id": "article-lead"})
        lead = (lead_tag.get_text(strip=True) if lead_tag else "")[:300]
        if lead_tag and len(lead_tag.get_text()) > 300: lead += "..."
        time_tag = article.find("time")
        published = time_tag["datetime"][:10] if time_tag and time_tag.get("datetime") else ""
        img_tag = article.find("img")
        image_url = None
        if img_tag and img_tag.get("src"):
            image_url = img_tag["src"]
            if image_url.startswith("//"): image_url = "https:" + image_url
            elif image_url.startswith("/"): image_url = "https://habr.com" + image_url
        return {"title": title, "link": link, "author": author, "lead": lead, "published": published, "image_url": image_url}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ Habr: {e}")
        return None


def get_top3_habr_articles():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://habr.com/ru/articles/", headers=headers, timeout=10)
        response.raise_for_status()
        if "captcha" in response.url or "cloudflare" in response.text.lower():
            return None
        soup = BeautifulSoup(response.text, "lxml")
        articles = soup.find_all("div", {"data-test-id": "article-snippet"}, limit=3)
        result = []
        for art in articles:
            title_tag = art.find("a", {"data-test-id": "article-title-link"})
            if not title_tag: continue
            title = title_tag.get_text(strip=True)
            link = "https://habr.com" + title_tag["href"] if title_tag["href"].startswith("/") else title_tag["href"]
            img_tag = art.find("img")
            image_url = None
            if img_tag and img_tag.get("src"):
                image_url = img_tag["src"]
                if image_url.startswith("//"): image_url = "https:" + image_url
                elif image_url.startswith("/"): image_url = "https://habr.com" + image_url
            result.append({"title": title, "link": link, "image_url": image_url})
        return result
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Ç–æ–ø-3 Habr: {e}")
        return None


# --- –ù–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ---

def get_vc_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://vc.ru/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("div.l-entry__content a") or soup.select_one("a.l-card")
        if not article: return None
        title = article.get_text(strip=True)
        link = article["href"] if article.has_attr("href") else ""
        if link.startswith("/"): link = "https://vc.ru" + link
        return {"title": title, "link": link, "source": "VC.ru"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ VC.ru: {e}")
        return None


def get_tproger_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://tproger.ru/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("h2.entry-title a") or soup.select_one("a.post-title")
        if not article: return None
        title = article.get_text(strip=True)
        link = article["href"]
        return {"title": title, "link": link, "source": "TProger"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ TProger: {e}")
        return None


def get_ria_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://ria.ru/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("a.cell-list__item-link") or soup.select_one("a[slot='text']")
        if not article: return None
        title = article.get_text(strip=True)
        link = article["href"]
        if link.startswith("/"): link = "https://ria.ru" + link
        return {"title": title, "link": link, "source": "–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ RIA: {e}")
        return None


def get_reuters_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://www.reuters.com/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("a[data-testid='Heading']") or soup.select_one("a[href^='/world/']")
        if not article: return None
        title = article.get_text(strip=True)
        link = article["href"]
        if link.startswith("/"): link = "https://www.reuters.com" + link
        return {"title": title, "link": link, "source": "Reuters"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ Reuters: {e}")
        return None


# --- –°—Ç–∞—Ä—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º) ---
def get_lenta_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://lenta.ru/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("div.top-item a") or soup.select_one("div.item a")
        if not article: return None
        title = article.get_text(strip=True)
        link = "https://lenta.ru" + article["href"] if article["href"].startswith("/") else article["href"]
        return {"title": title, "link": link, "source": "Lenta.ru"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ Lenta.ru: {e}")
        return None


def get_meduza_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://meduza.io/", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("a[rel='noopener']") or soup.select_one("a.SimpleBlock-article__link")
        if not article: return None
        title = article.get_text(strip=True)
        link = "https://meduza.io" + article["href"] if article["href"].startswith("/") else article["href"]
        return {"title": title, "link": link, "source": "Meduza"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ Meduza: {e}")
        return None


def get_bbc_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://www.bbc.com/news", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "lxml")
        article = soup.select_one("a[data-testid='internal-link'] h2")
        if not article: article = soup.select_one("a h3")
        if not article or not article.parent: return None
        title = article.get_text(strip=True)
        link = article.parent["href"]
        if link.startswith("/"): link = "https://www.bbc.com" + link
        return {"title": title, "link": link, "source": "BBC News"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ BBC: {e}")
        return None


# === –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò ===

@dp.message(CommandStart())
async def send_welcome(message: types.Message):
    user_id = message.from_user.id
    welcome_text = (
        f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.full_name}!\n"
        f"–Ø ‚Äî —É–º–Ω—ã–π –±–æ—Ç —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏, –º–µ–º–∞–º–∏ –∏ –∏–≥—Ä–∞–º–∏!\n\n"
        f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    )
    await message.answer(welcome_text, reply_markup=get_main_keyboard(user_id))


@dp.message(Command("menu"))
async def send_menu(message: types.Message):
    await message.answer("–ú–µ–Ω—é:", reply_markup=get_main_keyboard(message.from_user.id))


@dp.callback_query(lambda c: c.data == 'help')
async def process_help_callback(callback: types.CallbackQuery):
    await callback.answer()
    help_text = (
        "üîπ **–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ** ‚Äî –ø–æ–∑–¥–æ—Ä–æ–≤–∞—Ç—å—Å—è\n"
        "üîπ **–°–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ** ‚Äî –æ—Ç 1 –¥–æ 100\n"
        "üîπ **üé≠ –ú–µ–º** ‚Äî –ø–æ–ª—É—á–∏—Ç—å –º–µ–º\n"
        "üîπ **–ò–≥—Ä–∞** ‚Äî —É–≥–∞–¥–∞–π —á–∏—Å–ª–æ\n"
        "üîπ **Habr** ‚Äî —Å–≤–µ–∂–∏–µ IT-—Å—Ç–∞—Ç—å–∏\n"
        "üîπ **üì∞ –ù–æ–≤–æ—Å—Ç–∏** ‚Äî Lenta, Meduza, BBC, Reuters,\n"
        "   VC.ru, TProger, RIA\n"
        "üîπ **–î–∞—Ç–∞/–≤—Ä–µ–º—è** ‚Äî —Ç–µ–∫—É—â–∏–µ\n"
        "üîπ **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** ‚Äî –ø–æ –∏–≥—Ä–∞–º"
    )
    if callback.from_user.id == OWNER_ID:
        help_text += "\nüîπ **–°–µ–∫—Ä–µ—Ç** ‚Äî –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–∞"
    try:
        await callback.message.edit_text(help_text, reply_markup=get_main_keyboard(callback.from_user.id))
    except TelegramBadRequest as e:
        if "message is not modified" not in str(e): raise


# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ (greet, random_number, random_meme, start_game, latest_habr, top3_habr, datetime, stats, secret, handle_message) –æ—Å—Ç–∞—é—Ç—Å—è –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ...

# === –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π ===

@dp.callback_query(lambda c: c.data == 'news_menu')
async def process_news_menu_callback(callback: types.CallbackQuery):
    await callback.answer()
    await callback.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫:", reply_markup=get_news_sources_keyboard())


@dp.callback_query(lambda c: c.data.startswith('news_'))
async def process_news_callback(callback: types.CallbackQuery):
    source = callback.data
    await callback.answer("–ó–∞–≥—Ä—É–∂–∞—é...", show_alert=False)

    article = None
    if source == "news_lenta": article = get_lenta_news()
    elif source == "news_meduza": article = get_meduza_news()
    elif source == "news_bbc": article = get_bbc_news()
    elif source == "news_reuters": article = get_reuters_news()
    elif source == "news_vc": article = get_vc_news()
    elif source == "news_tproger": article = get_tproger_news()
    elif source == "news_ria": article = get_ria_news()

    if not article:
        await callback.message.edit_text(
            "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_news_sources_keyboard()
        )
        return

    title = escape_markdown_v2(article["title"])
    link = article["link"]
    source_name = article["source"]
    caption = f"üì∞ **{source_name}**\n\n[{title}]({link})"

    try:
        await callback.message.edit_text(caption, parse_mode="MarkdownV2", reply_markup=get_news_sources_keyboard())
    except TelegramBadRequest:
        fallback = f"üì∞ {source_name}\n\n{article['title']}\n\n–ß–∏—Ç–∞—Ç—å: {link}"
        await callback.message.edit_text(fallback, reply_markup=get_news_sources_keyboard())


@dp.callback_query(lambda c: c.data == 'back_to_main')
async def process_back_to_main(callback: types.CallbackQuery):
    await callback.answer()
    await callback.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=get_main_keyboard(callback.from_user.id))


# === –û–°–¢–ê–õ–¨–ù–´–ï –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ===
# (greet, random_number, random_meme, start_game, latest_habr, top3_habr, datetime, stats, secret, handle_message)
# ‚Üí –æ–Ω–∏ —É–∂–µ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ, –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤—å—Ç–µ –∏—Ö –∫–∞–∫ –µ—Å—Ç—å!

# –î–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –Ω–µ –¥—É–±–ª–∏—Ä—É—é –∏—Ö –∑–¥–µ—Å—å, –Ω–æ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ –æ–Ω–∏ –î–û–õ–ñ–ù–´ –ë–´–¢–¨!

# === –ó–ê–ü–£–°–ö ===

async def main():
    logging.info("‚úÖ –ë–æ—Ç —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∑–∞–ø—É—â–µ–Ω!")
    await dp.start_polling(bot)


if __name__ == '__main__':
    asyncio.run(main())